%
% Einführung in die Mustererkennung - WS2013
% Abgabeprotokoll Exercise 1
%
%

%{{{ misc
\documentclass[a4paper,psfig,subfigure,epsfig,fleqn,amssmb,float,caption,fontenc,ausarbeitung]{article}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\usepackage{pgfplots}

%Zitieren:
\usepackage[english]{babel}
%\usepackage[german]{babel}
\usepackage{babelbib} % für das Erstellen des Bibtex-Literaturverzeichnisses
\usepackage{cite}
%\selectbiblanguage{english}
%\selectbiblanguage{german}


\usepackage{url}

\usepackage[]{mcode}

\usepackage[pdftitle={Einfuehrung in die Mustererkennung, Exercise 1},
            pdfauthor={David Pfahler},
						pdfauthor={Matthias Gusenbauer},
						pdfauthor={Matthias Vigele},
            pdfsubject={Mustererkennung},
            pdfborder={0 0 0}]{hyperref}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Titlepage

\pagestyle{empty}


%set dimensions of columns, gap between columns, and paragraph indent

\setlength{\textheight}{24.7 cm}
\setlength{\columnsep}{1 cm}
\setlength{\textwidth}{16 cm}
%\setlength{\footheight}{0.0 cm}
\setlength{\topmargin}{0.0 cm}
\setlength{\headheight}{0.0 cm}
\setlength{\headsep}{-0.3 cm}
\setlength{\oddsidemargin}{0.0 cm}
\setlength{\parindent}{0.7 cm}
\setlength{\mathindent}{0mm}

% set page counter if document is part of proceedings
\setcounter{page}{1}
\renewcommand{\floatpagefraction}{0.9}
\renewcommand{\textfraction}{0.1}

%\renewcommand{\captionlabelfont}{\fontfamily{phv}\fontseries{bx}\fontsize{10}{10pt}\selectfont}
%\renewcommand{\captionfont}{\fontfamily{phv}\fontsize{10}{12pt}\selectfont}
%\setlength{\captionmargin}{0.5 cm}

\makeatletter
\makeatother
\def\RR{\hbox{I\kern-.2em\hbox{R}}}


\begin{document}

%don't want date printed
\date{}

%make title bold and 14 pt font (Latex default is non-bold, 16pt) 
\title{~\\
  ~\\
  \fontsize{14}{14pt} \bf Abgabedokument Exercise 1
	 ~\\
  \fontsize{12}{12pt} \bf Einführung in die Mustererkennung 186.840 WS 2013}

%for single author 
\author{~\\
  ~\\
  \fontsize{12}{12pt}
  {\bf David Pfahler, Matthias Gusenbauer, Matthias Vigele}\\
  1126287, 1125577, 1126171
  ~\\ ~\\ ~\\
  \normalsize
}

\maketitle
%I don't know why I have to reset thispagestyle, but otherwise get page numbers 
\normalfont
\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONTENT

\section{Feature Extraction}
\label{sec:featureExtraction}

This section describes the used image classes and the features that are used for the classification (see Section \ref{sec:classification}. 

\subsection{Input Images}
\label{sec:input}

5 Classes from the MPEG7 CE-Shape-1 database \cite{latecki2000shape} are used. We used:

\begin{itemize}
	\item Heart
	\item device4
	\item bat
	\item device1
	\item Bone
\end{itemize}

Figure \ref{fig:classes} shows example images of the used classes.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/Heart-1}
		\caption{Heart}
	\end{subfigure}
	~ 
	\begin{subfigure}[b]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/Bone}
		\caption{Bone}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/device1}
		\caption{device1}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/device4}
		\caption{device4}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.3\textwidth}
		\includegraphics[width=\textwidth]{img/bat}
		\caption{bat}
	\end{subfigure}
	~
	\caption{5 used Classes from the MPEG7 CE-Shape-1 database \cite{latecki2000shape}}
	\label{fig:classes}
\end{figure}


\subsection{Features}
\label{sec:features}

In the following section the used features are described. To evaluate scale, 
transformation and rotation invariants a test image is used. Listing 
\ref{lst:calcRot} shows the used matlab function. Figure \ref{fig:heart} 
shows the test image. 

\begin{lstlisting}[caption=Calculate rotated image, label=lst:calcRot]
	rot = imresize(imrotate(image,45),0.5);
\end{lstlisting}
The calculation of the features of the two test images will differ, because 
of the lost of accuracy by the size reduction.

\subsubsection{Eccentricity}
\label{sec:eccentricity}

The Eccentricity is a scalar value that measures of how much the object 
deviates from a circle. It is calculated by the ratio of the distance between 
the foci of the ellipse and its major axis length. See Equation 
\ref{eq:eccentricity}
\begin{equation}
	\frac{2*\sqrt{\frac{D_{max}}{2}^2-\frac{D_{min}}{2}^2}}{D_{max}}
	\label{eq:eccentricity}
\end{equation}
$D_{max}$ is the major axis length and $D_{min}$ is the minor axis length of 
the best-fit ellipse.

\paragraph{Invariance:} The eccentricity feature is scale, transformation and 
rotation invariant. The Listing \ref{lst:eccentricity} provides an example. 
Figure \ref{fig:heart} shows the used binary images.

\begin{lstlisting}[caption=Calculate eccentricity in matlab, label=lst:eccentricity]
>> regionprops(image,'Eccentricity')

ans = 

    Eccentricity: 0.7073

>> regionprops(rot,'Eccentricity')

ans = 

    Eccentricity: 0.7080
\end{lstlisting}

\subsubsection{Roundness}
\label{sec:roundness}

Roundness is a scalar value that describe how the shape of an object 
approaches that of a circle. A value of 1 means that the object is a circle 
and a value of 0 means the object is a line segment. See Equation \ref{eq:roundness}
\begin{equation}
  \frac{4A(R)}{\pi D^{2}_{max}}
	\label{eq:roundness}
\end{equation}
$A(R)$ is the area of the labeled binary image and $D_{max}$ is the major axis 
length of the best-fit ellipse.

\paragraph{Invariance:} The Roundness feature is scale, transformation and 
rotation invariant. The Listing \ref{lst:roundness} provides an example. 
Figure \ref{fig:heart} shows the used binary images.

\begin{lstlisting}[caption=Calculate roundness in matlab, label=lst:roundness]
	>> calculateRoundness(image)

	ans = 

			Roundness: 0.6333
	
	>> calculateRoundness(rot)

	ans = 

			Roundness: 0.6326
\end{lstlisting}

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{img/heart.jpg}
	\end{subfigure}
	~ 
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{img/invariance_rotation.jpg}
	\end{subfigure}
	\caption{A rotated, translated and scaled image}
	\label{fig:heart}
\end{figure}


\subsubsection{Solidity}
\label{sec:solidity}

The solidity is a scalar value specifying the proportion of the pixels in the 
convex hull that are also in the region. See Equation \ref{eq:solidity}

\begin{equation}
\frac{A(R)}{A(Co(R))}
\label{eq:solidity}
\end{equation}
$A(R)$ is the area of the labeled binary image and $Co(R)$ is the convex hull of the binary image

\paragraph{Invariance:} The solidity feature is scale, transformation and 
rotation invariant. The Listing \ref{lst:solidity} provides an example. 
Figure \ref{fig:heart} shows the used binary images.
\begin{lstlisting}[caption=Calculate solidity in matlab, label=lst:solidity]
>> regionprops(image,'Solidity')

ans = 

    Solidity: 0.9145

>> regionprops(rot,'Solidity')

ans = 

    Solidity: 0.9113
\end{lstlisting}

\subsection{Results}
\label{sec:fResults}

With the {\tt matlab} function {\tt getFeatures} all features for all input 
images (see Section \ref{sec:input}) are calculated. In Figure \ref{fig:boxplot} 
a boxplot  of this features is shown. The boxplot is a convenient way of 
graphically depicting groups of numerical data through their quartiles. 
\cite{tukey1977exploratory}
The Figure \ref{fig:gscatter} shows the dependencies of all features and displays outliers.

\begin{figure}
	\centering
	\newlength\figureheight 
	\newlength\figurewidth 
	\setlength\figureheight{6cm} 
	\setlength\figurewidth{10cm}
	\input{img/boxplot.tex}
	\caption{Boxplot of all features}
	\label{fig:boxplot}
\end{figure}

\begin{figure}
	\centering
	\setlength\figureheight{4cm} 
	\setlength\figurewidth{10cm}
	\input{img/gscatter.tikz}
	\caption{Scatterplot of all features in relation}
	\label{fig:gscatter}
\end{figure}







\section{Classification}
\label{sec:classification}
This section describes the two classification algorithms, one is hand-tuned (see Section \ref{sec:own}) and the other k-NN-based (see Section \ref{sec:kNN}), that are used to classify the images. Both of these algorithms use the feature values described in Section \ref{sec:features} to distinguish between the five classes mentioned in Section \ref{sec:input}.

\subsection{Own Implementation}
\label{sec:own}
Our classification algorithm uses thresholds on the feature values to determine the class of an image.

\subsubsection{Methods}
\label{sec:ownMethods}
The {\tt matlab} function {\tt customClassifier} takes all the computed feature values (see Section \ref{sec:fResults}) as input to classify the images.
Various thresholds are used to distinguish between the five classes. For example (see Listing \ref{lst:solidity}): An image with an eccentricity value greater than or equal to 0.8 could be a member of either the "bat" or the "heart" class. But it is possible to distinguish the two classes by taking another feature value into account: The image has to be a member of the  "heart" class, if its roundness value is also greater than or equal to 0.4.

\begin{lstlisting}[caption=Example for two thresholds, label=lst:thresholdEx]
       if(featureV(1)>=0.8)
           %bat or heart
           classNames{i}='bat';         
           %roundness threshold
           if(featureV(2)>=0.4)
           %heart
           classNames{i}='Heart';                     
           end
       end
\end{lstlisting}

\subsubsection{Results}
\label{sec:ownResults}
Our classifier classifies 100\% of the objects correctly.

\subsection{k-NN Classifier}
\label{sec:kNN}
The k-NN Classifier uses a set of pre-classified feature vectors to classify another set of feature vectors.

\subsubsection{Methods}
\label{sec:kNNMethods}
The {\tt matlab} function {\tt k\_NN} classifies an feature vector by computing its k nearest neighbours (using the Euclidean distance) in the training set, and labeling the image with the class name that is most common among these neighbours.

\subsubsection{Results}
\label{sec:kNNResults}
As shown in Figure \ref{fig:results}, the number of correctly classified images drops significally with increasing k.
\begin{figure}
	\centering
	\setlength\figureheight{7cm} 
	\setlength\figurewidth{9cm}
	\input{img/results.tikz}
	\caption{\% of correct classifications with varying k}
	\label{fig:results}
\end{figure}

\section{Paper Summary}
\label{sec:paperSummary}
 \cite{beyer1999nearest}

In the paper "When Is 'Nearest Neighbor' Meaningful?" Kevin Beyer, Jonathan Goldstein, Raghu Ramakrishnan and Uri Shaft analyse that “Nearest Neighbor” or NN ist not a good general purpose tool for scientists to work with. Their biggest critic is that this method is used in almost all the database literature to evaluate high-dimensional indexing while it is not a good practice to use NN for high-dimensional indexing techniques. Furthermore it is said that most literature does not compare the described techniques with the simple linear scan. According to the shown evaluation in the paper this simple technique almost always outperforms the given methods in the literature. Lastly Beyer, Goldstein, Ramakrishnan and Shaft showed that the evaluated workload is not even meaningful for “Nearest Neighbor”.In the Introduction they summarize their three contributions in this paper. 
\paragraph{}
The first and presumably the most important statement is that with the increase in dimensionality the distance from a query point to the nearest data point converges against the distance to the farthest neighbor. Thus with increasing dimensions the significance of the result of the NN-algorithm is greatly reduced up to a point where the authors of the paper call the output unstable. In addition they not only show that this behaviour is not algorithm dependent but rather a general problem of NN. \\
The second part is a practical application of their theoretical findings. The authors provide empirical results based on synthetic distributions and, to add real world perspectives, they examined results provided by experiments on real data gathered from a real image database. It is shown that the impact of the effect described above is not to be neglected. \\
Another very important finding is that NN does not necessarily fail with higher dimensions in general. It is stated that there are certain circumstances where NN is still meaningful and therefore a good tool. The authors emphasise in general that it is not their intention to render NN useless but rather show that NN should not be misused without any thorough consideration of the data set.\\
The third main statement is that most of the database literature fails to compare their nearest neighbor processing techniques to the simple linear scans. The evaluation done in this paper concludes that the linear scan out-performs the techniques investigated in the given literature in almost every case. It is described that NN fails against linear scan because they use their techniques on workloads  in high dimensionality which “behave badly” in the way described before.
\paragraph{}
In the next step the authors show us circumstances where the nearest neighbour obviously fails. Such scenarios could be if the datapoints are not certain but rather given as a confidence circle as to where their position may be or if the data points are located circular and the query point is close to the center of the circle. Then the difference of the distance to the nearest neighbor and other neighbors would be fairly small. 
A more general case would be if you take the distance from the query point to the nearest neighbor as the radios of a circle and add a certain epsilon value to it. If there are many or even most other data points within this new circle then the result may be considered not significant or unstable. 
\paragraph{}

The next section outlines scenarios where NN is a valid and good practice. Such scenarios could be when the query point is identical with a datapoint and when there are no duplicate datapoints. This can even be generalised a little. If you assume that the query point is within a small distance to a data point you can still get meaningful results. With increasing dimensionality the query point has to decrease its distance from the data point for the result to stay meaningful. \\
The paper generalises this approach even more. If the data points are located close together so they form a cluster with a given radius then if the query point falls into that cluster of points the results given by the nearest neighbor algorithm are still meaningful. This case is perfect for classification problems. However if the query point does not fall into or close to a cluster or even if the clusters are close together and the query point does not have a obvious closest cluster then NN can not considered to perform good results anymore.
The last stated case where NN results in an expressive outcome is when the underlying dimensionality of the data is much lower than the actual dimensionality. Such a case can be achieved by using the principle component analysis to find meaningful dimensions and only perform work on these to get good results. \\
The experiments the authors ran on datasets showed that the difference in length of the closest and farthest datapoint are gets small within a few dimensions. For example the contrast of $ d_{max} / d_{min} $ at 10 dimensions gets reduced by the order of 6 in magnitude. When increased to 20 dimensions the farthest point has only 4 times $ d_min $. Based on these results the authors conclude that NN becomes already unstable at 10 to 20 dimensions.\\
Lastly the paper continues to lament the fact that literature fails to evaluate their techniques using meaningful and stable datasets. Furthermore it is once again said that literature does not compare their techniques with simple linear scan algorithms. In most cases the linear scan algorithm outperforms the given NN solutions.
 \pagebreak
% Biblography


\fontsize{9}{10pt}
\bibliographystyle{plain}
\bibliography{literatur}

\end{document}

% vim:foldmethod=marker
